{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from torchvision import io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms.functional as T\n",
    "from torchvision.transforms import Resize, RandomCrop, Normalize\n",
    "from torchvision.models.detection import MaskRCNN\n",
    "from torch import nn, device\n",
    "import random\n",
    "\n",
    "DATA_DIR = \"C:\\\\New folder\\\\Dr. Surya\\\\MaskRCNN\\\\Unity_Generation\\\\Concrete\"\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, \"Images\")\n",
    "MASKS_DIR = os.path.join(DATA_DIR, \"Masks\") \n",
    "ANNOTATIONS_DIR = os.path.join(DATA_DIR, \"BoundingBoxs\")\n",
    "def get_annotations_file_path(image_filename):\n",
    "  filename_without_extension = os.path.splitext(image_filename)[0]\n",
    "  return os.path.join(ANNOTATIONS_DIR, f\"{filename_without_extension}.json\")\n",
    "\n",
    "class CrackDataset(Dataset):\n",
    "\n",
    "  def __init__(self, root_dir):\n",
    "\n",
    "    self.root_dir = root_dir\n",
    "    \n",
    "    # Load image names\n",
    "    self.images = os.listdir(IMAGES_DIR) \n",
    "\n",
    "    # Load mask names \n",
    "    self.masks = os.listdir(MASKS_DIR)\n",
    "\n",
    "    # Load annotations\n",
    "    with open(ANNOTATIONS_DIR) as f:\n",
    "      self.annotations = json.load(f)\n",
    "\n",
    "  def __getitem__(self, i):\n",
    "\n",
    "    # Get image name\n",
    "    image_name = self.images[i]\n",
    "\n",
    "    # Get mask name\n",
    "    mask_name = self.masks[i] \n",
    "\n",
    "    # Get annotations \n",
    "    annotations = self.annotations[image_name]\n",
    "\n",
    "    # Read image and mask\n",
    "    image = io.read_image(os.path.join(IMAGES_DIR, image_name))\n",
    "    mask = io.read_image(os.path.join(MASKS_DIR, mask_name))\n",
    "\n",
    "    return image, mask, annotations\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "\n",
    "def transform(image, mask):\n",
    "\n",
    "  # Resize images \n",
    "  resized = Resize(256)\n",
    "  image = resized(image)\n",
    "  mask = resized(mask)\n",
    "\n",
    "  # Apply random crop\n",
    "  random_crop = RandomCrop(224,224)  \n",
    "  image, mask = random_crop(image, mask)\n",
    "\n",
    "  # Apply horizontal flip\n",
    "  if random.random() < 0.5:\n",
    "    image = T.hflip(image)  \n",
    "    mask = T.hflip(mask)\n",
    "\n",
    "  # Normalize image\n",
    "  normalized = Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "  image = normalized(image)\n",
    "\n",
    "  # Convert to tensors\n",
    "  image = T.to_tensor(image)  \n",
    "  mask = torch.squeeze(mask, dim=0)\n",
    "\n",
    "  return image, mask\n",
    "\n",
    "dataset = CrackDataset(DATA_DIR)\n",
    "dataloader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "#Split dataset into train and val\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False, \n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "model = MaskRCNN(backbone='resnet50', pretrained=True, pretrained_backbone=True)\n",
    "for param in model.features.parameters():\n",
    "  param.requires_grad = False\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "\n",
    "   # training \n",
    "   for images, targets in train_dataloader:\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, targets)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      \n",
    "   # validation\n",
    "   with torch.no_grad():\n",
    "\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "\n",
    "    for images, targets in val_dataloader:\n",
    "\n",
    "      images = images.to(device)\n",
    "      targets = targets.to(device)\n",
    "\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, targets)\n",
    "\n",
    "      val_loss += loss.item()\n",
    "\n",
    "      predictions = torch.argmax(outputs, dim=1)\n",
    "      actual = targets\n",
    "      accuracy = (predictions == actual).float().mean()\n",
    "      val_accuracy += accuracy\n",
    "\n",
    "    val_loss /= len(val_dataloader)\n",
    "    val_accuracy /= len(val_dataloader)\n",
    "\n",
    "    print(f\"Val Loss: {val_loss}, Val Accuracy: {val_accuracy}\")\n",
    "\n",
    "# Save trained model\n",
    "torch.save(model.state_dict(), 'C:\\\\New folder\\\\Dr. Surya\\\\MaskRCNN\\\\crack_maskrcnn.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
